import tkinter as tk
from tkinter import filedialog, messagebox, scrolledtext
import subprocess
import shutil
import os
import threading
import asyncio
import nest_asyncio
import re
import edge_tts
import time

# Apply nest_asyncio ƒë·ªÉ ch·∫°y asyncio trong m√¥i tr∆∞·ªùng c√≥ loop s·∫µn (nh∆∞ Tkinter)
nest_asyncio.apply()

# ==============================================================================
# ‚öôÔ∏è C·∫§U H√åNH M·∫∂C ƒê·ªäNH
# ==============================================================================
GIONG_DOC_DEFAULT = "vi-VN-HoaiMyNeural"
MAX_SPEED_INCREASE = 100 
TEMP_FOLDER = "temp_processing"

class AutoDubberApp:
    def __init__(self, root):
        self.root = root
        self.root.title("TDTU Auto Dubber - AI TTS & Video Mixer v3.1 (Fix Path)")
        self.root.geometry("700x650")
        self.root.resizable(False, False)

        # --- Variables ---
        self.video_path = tk.StringVar()
        self.script_path = tk.StringVar()
        self.status_var = tk.StringVar(value="S·∫µn s√†ng...")
        
        # T√¨m FFmpeg ngay khi kh·ªüi ƒë·ªông
        self.ffmpeg_path = self._find_tool("ffmpeg")
        self.ffprobe_path = self._find_tool("ffprobe")

        # --- UI Layout ---
        self.create_widgets()

        if not self.ffmpeg_path:
            messagebox.showerror("L·ªói M√¥i Tr∆∞·ªùng", "Kh√¥ng t√¨m th·∫•y FFmpeg! Vui l√≤ng c√†i ƒë·∫∑t FFmpeg v√† th√™m v√†o PATH.")

    def _find_tool(self, tool_name):
        path = shutil.which(tool_name)
        if path: return path
        possible_paths = [
            os.path.expandvars(rf"%LOCALAPPDATA%\Microsoft\WinGet\Links\{tool_name}.exe"),
            rf"C:\ffmpeg\bin\{tool_name}.exe",
            rf"D:\ffmpeg\bin\{tool_name}.exe"
        ]
        for p in possible_paths:
            if os.path.exists(p): return p
        return None

    def create_widgets(self):
        # Header
        lbl_title = tk.Label(self.root, text="AUTOMATIC AI DUBBING TOOL", font=("Segoe UI", 16, "bold"), fg="#c0392b")
        lbl_title.pack(pady=10)

        # 1. Ch·ªçn Video G·ªëc
        grp_video = tk.LabelFrame(self.root, text="1. Video G·ªëc (Background)", padx=10, pady=5)
        grp_video.pack(fill="x", padx=10, pady=5)
        tk.Entry(grp_video, textvariable=self.video_path, width=70).pack(side="left", padx=5)
        tk.Button(grp_video, text="üìÇ Video", command=self.browse_video).pack(side="left")

        # 2. Ch·ªçn Script
        grp_script = tk.LabelFrame(self.root, text="2. File K·ªãch b·∫£n (.txt - Format: [start->end] Text)", padx=10, pady=5)
        grp_script.pack(fill="x", padx=10, pady=5)
        tk.Entry(grp_script, textvariable=self.script_path, width=70).pack(side="left", padx=5)
        tk.Button(grp_script, text="üìÑ Script", command=self.browse_script).pack(side="left")

        # 3. Mixer (Volume)
        grp_vol = tk.LabelFrame(self.root, text="3. Mixer Control", padx=10, pady=5)
        grp_vol.pack(fill="x", padx=10, pady=5)

        # Grid layout cho mixer
        tk.Label(grp_vol, text="Volume Video G·ªëc:").grid(row=0, column=0, sticky="w", padx=5)
        self.vol_video_slider = tk.Scale(grp_vol, from_=0, to=200, orient="horizontal", length=200)
        self.vol_video_slider.set(80) # Gi·∫£m nh·∫°c n·ªÅn xu·ªëng
        self.vol_video_slider.grid(row=0, column=1)

        tk.Label(grp_vol, text="Volume Gi·ªçng AI:").grid(row=0, column=2, sticky="w", padx=5)
        self.vol_ai_slider = tk.Scale(grp_vol, from_=0, to=200, orient="horizontal", length=200)
        self.vol_ai_slider.set(150) # TƒÉng gi·ªçng ƒë·ªçc l√™n
        self.vol_ai_slider.grid(row=0, column=3)

        # 4. Console Log (ƒê·ªÉ d√¢n Dev nh√¨n cho chuy√™n nghi·ªáp)
        grp_log = tk.LabelFrame(self.root, text="Process Logs", padx=10, pady=5)
        grp_log.pack(fill="both", expand=True, padx=10, pady=5)
        self.log_area = scrolledtext.ScrolledText(grp_log, height=10, state='disabled', font=("Consolas", 9))
        self.log_area.pack(fill="both", expand=True)

        # 5. Action Button
        self.btn_run = tk.Button(self.root, text="üöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù (RENDER)", command=self.start_processing_flow, 
                                 bg="#2ecc71", fg="white", font=("Segoe UI", 12, "bold"), height=2)
        self.btn_run.pack(fill="x", padx=20, pady=10)

        # Status Bar
        self.lbl_status = tk.Label(self.root, textvariable=self.status_var, relief=tk.SUNKEN, anchor="w")
        self.lbl_status.pack(side="bottom", fill="x")

    def log(self, message):
        self.log_area.config(state='normal')
        self.log_area.insert(tk.END, f"[{time.strftime('%H:%M:%S')}] {message}\n")
        self.log_area.see(tk.END)
        self.log_area.config(state='disabled')

    # --- File Dialogs ---
    def browse_video(self):
        path = filedialog.askopenfilename(filetypes=[("Video Files", "*.mp4 *.mkv *.avi")])
        if path: self.video_path.set(path)

    def browse_script(self):
        path = filedialog.askopenfilename(filetypes=[("Text Files", "*.txt")])
        if path: self.script_path.set(path)

    # --- Core Logic ---
    def start_processing_flow(self):
        # 1. Validate
        if not self.video_path.get() or not self.script_path.get():
            messagebox.showwarning("Thi·∫øu d·ªØ li·ªáu", "Vui l√≤ng ch·ªçn Video v√† Script!")
            return
        
        # 2. Save location
        output_path = filedialog.asksaveasfilename(
            title="L∆∞u video k·∫øt qu·∫£", defaultextension=".mp4",
            filetypes=[("MP4 Video", "*.mp4")], initialfile="Video_Final_AI_Dubbed.mp4"
        )
        if not output_path: return

        # 3. Start Thread
        self.btn_run.config(state="disabled", text="‚è≥ ƒêang x·ª≠ l√Ω... Vui l√≤ng ƒë·ª£i")
        threading.Thread(target=self.process_pipeline, args=(output_path,), daemon=True).start()

    def process_pipeline(self, output_path):
        try:
            self.log("=== B·∫ÆT ƒê·∫¶U PIPELINE ===")
            
            # B1: Chu·∫©n b·ªã th∆∞ m·ª•c temp (T·∫°o ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ngay t·ª´ ƒë·∫ßu)
            abs_temp_folder = os.path.abspath(TEMP_FOLDER)
            if os.path.exists(abs_temp_folder): shutil.rmtree(abs_temp_folder, ignore_errors=True)
            os.makedirs(abs_temp_folder)
            self.log(f"Temp folder: {abs_temp_folder}")

            # B2: ƒê·ªçc script
            self.status_var.set("ƒêang ƒë·ªçc k·ªãch b·∫£n...")
            subtitles = self.read_script_file(self.script_path.get())
            if not subtitles:
                raise Exception("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c script ho·∫∑c script r·ªóng!")
            self.log(f"ƒê√£ t√¨m th·∫•y {len(subtitles)} c√¢u tho·∫°i.")

            # B3: T·∫°o Audio TTS ho√†n ch·ªânh
            self.status_var.set("ƒêang sinh gi·ªçng ƒë·ªçc AI...")
            full_audio_path = os.path.join(abs_temp_folder, "full_tts_track.mp3").replace("\\", "/")
            self.create_tts_track(subtitles, full_audio_path, abs_temp_folder)

            # B4: Tr·ªôn Video + Audio TTS
            self.status_var.set("ƒêang render video cu·ªëi c√πng...")
            # Ki·ªÉm tra xem file audio ƒë√£ ƒë∆∞·ª£c t·∫°o ch∆∞a tr∆∞·ªõc khi mix
            if not os.path.exists(full_audio_path):
                 raise Exception(f"L·ªói nghi√™m tr·ªçng: Kh√¥ng t√¨m th·∫•y file audio ƒë√£ sinh ra t·∫°i {full_audio_path}")

            self.mix_video_audio(self.video_path.get(), full_audio_path, output_path)

            self.status_var.set("Ho√†n t·∫•t!")
            self.log(f"=== XONG! File l∆∞u t·∫°i: {output_path} ===")
            messagebox.showinfo("Th√†nh c√¥ng", "ƒê√£ x·ª≠ l√Ω xong video!")
            # M·ªü file ho·∫∑c th∆∞ m·ª•c ch·ª©a file
            if os.name == 'nt':
                 try:
                    os.startfile(output_path)
                 except: pass

        except Exception as e:
            self.log(f"ERROR: {str(e)}")
            messagebox.showerror("L·ªói", str(e))
        finally:
            # Cleanup (C√≥ th·ªÉ comment d√≤ng n√†y n·∫øu mu·ªën debug file trong temp)
            if os.path.exists(TEMP_FOLDER): shutil.rmtree(TEMP_FOLDER, ignore_errors=True)
            self.root.after(0, lambda: self.btn_run.config(state="normal", text="üöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù (RENDER)"))

    # --- TTS GENERATOR LOGIC ---
    def read_script_file(self, file_path):
        data = []
        pattern = re.compile(r"\[([\d\.]+)s\s*->\s*([\d\.]+)s\]\s*(.*)")
        with open(file_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line: continue 
                match = pattern.match(line)
                if match:
                    try:
                        data.append({
                            'start': float(match.group(1)), 
                            'end': float(match.group(2)), 
                            'text': match.group(3).strip()
                        })
                    except ValueError: pass
        data.sort(key=lambda x: x['start'])
        return data

    def _get_audio_duration(self, file_path):
        try:
            cmd = [self.ffprobe_path, "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", file_path]
            # Th√™m startupinfo ƒë·ªÉ ·∫©n c·ª≠a s·ªï console ƒëen x√¨ khi ch·∫°y
            startupinfo = subprocess.STARTUPINFO()
            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, startupinfo=startupinfo)
            return float(result.stdout.strip())
        except: return 0.0

    def _create_silent_file(self, filename, duration=600):
        # T·∫°o file im l·∫∑ng, d√πng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi
        cmd = [self.ffmpeg_path, "-y", "-f", "lavfi", "-i", "anullsrc=r=24000:cl=mono", "-t", str(duration), "-c:a", "libmp3lame", filename]
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, startupinfo=startupinfo)

    async def _generate_clip(self, text, filename, rate_str="+0%"):
        communicate = edge_tts.Communicate(text, GIONG_DOC_DEFAULT, rate=rate_str, volume="+0%")
        await communicate.save(filename)

    def create_tts_track(self, subtitles, output_file, temp_folder):
        # S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi cho file silence
        silent_file = os.path.join(temp_folder, "silence.mp3").replace("\\", "/")
        self._create_silent_file(silent_file)

        concat_list_path = os.path.join(temp_folder, "mylist.txt").replace("\\", "/")
        current_cursor = 0.0
        
        with open(concat_list_path, "w", encoding='utf-8') as f:
            for i, item in enumerate(subtitles):
                slot_duration = item['end'] - item['start']
                # S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi cho t·ª´ng clip nh·ªè
                temp_filename = os.path.join(temp_folder, f"clip_{i}.mp3").replace("\\", "/")
                
                # Gap Before
                gap_before = item['start'] - current_cursor
                if gap_before > 0.01:
                    f.write(f"file '{silent_file}'\n")
                    f.write(f"inpoint 0\n")
                    f.write(f"outpoint {gap_before}\n")
                    current_cursor = item['start']

                # Generate Audio
                if item['text']:
                    self.log(f"Processing: {item['text'][:30]}...")
                    asyncio.run(self._generate_clip(item['text'], temp_filename))
                    actual_duration = self._get_audio_duration(temp_filename)

                    # Time Stretching logic
                    if actual_duration > slot_duration:
                        ratio = actual_duration / slot_duration
                        increase_percent = int((ratio - 1) * 100) + 10
                        increase_percent = min(increase_percent, MAX_SPEED_INCREASE)
                        self.log(f"  -> TƒÉng t·ªëc +{increase_percent}% ƒë·ªÉ kh·ªõp")
                        asyncio.run(self._generate_clip(item['text'], temp_filename, rate_str=f"+{increase_percent}%"))
                        actual_duration = self._get_audio_duration(temp_filename)
                    
                    # Quan tr·ªçng: Ghi ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi v√†o file list
                    f.write(f"file '{temp_filename}'\n")
                
                # Padding After (n·∫øu n√≥i xong s·ªõm)
                remaining = slot_duration - actual_duration
                if remaining > 0.01:
                    f.write(f"file '{silent_file}'\n")
                    f.write(f"inpoint 0\n")
                    f.write(f"outpoint {remaining}\n")
                
                current_cursor = item['end']

        # Concat Audio segments
        self.log("ƒêang gh√©p n·ªëi c√°c ƒëo·∫°n audio...")
        cmd = [self.ffmpeg_path, "-y", "-f", "concat", "-safe", "0", "-i", concat_list_path, "-c", "copy", output_file]
        
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        
        # Th√™m check=True ƒë·ªÉ b·∫Øt l·ªói ngay n·∫øu ffmpeg concat th·∫•t b·∫°i
        # B·ªè stderr=subprocess.DEVNULL ƒë·ªÉ n·∫øu l·ªói th√¨ in ra log
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, startupinfo=startupinfo)
        
        if result.returncode != 0:
            self.log(f"FFmpeg Concat Error:\n{result.stderr}")
            raise Exception("L·ªói khi gh√©p n·ªëi audio (FFmpeg concat failed)")

    # --- MIXER LOGIC ---
    def mix_video_audio(self, video_in, audio_in, video_out):
        vol_v = self.vol_video_slider.get() / 100.0
        vol_a = self.vol_ai_slider.get() / 100.0

        filter_complex = (
            f"[0:a]volume={vol_v}[original];"
            f"[1:a]volume={vol_a}[new];"
            f"[original][new]amix=inputs=2:duration=first:dropout_transition=0[aout]" 
            # duration=first: l·∫•y ƒë·ªô d√†i theo video g·ªëc
        )

        cmd = [
            self.ffmpeg_path, "-y",
            "-i", video_in,
            "-i", audio_in,
            "-filter_complex", filter_complex,
            "-map", "0:v:0",    
            "-map", "[aout]",   
            "-c:v", "copy",     # Copy video stream cho nhanh
            "-c:a", "aac",
            "-shortest",       
            video_out
        ]
        
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        
        # B·∫Øt l·ªói khi mix
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, startupinfo=startupinfo)
        if result.returncode != 0:
             self.log(f"FFmpeg Mix Error:\n{result.stderr}")
             raise Exception("L·ªói khi tr·ªôn Video (FFmpeg mix failed)")

if __name__ == "__main__":
    try:
        root = tk.Tk()
        app = AutoDubberApp(root)
        root.mainloop()
    except Exception as e:
        print(f"Critical Error: {e}")